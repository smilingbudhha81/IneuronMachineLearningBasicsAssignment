{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. In a linear equation, what is the difference between a dependent variable and an independent variable?\n",
    "\n",
    "ANS = \n",
    "\n",
    "Algebraically, a linear equation typically takes the form y = mx + b, where m and b are constants, x is the independent variable, y is the dependent variable. The slope tells us how the dependent variable (y) changes for every one unit increase in the independent (x) variable, on average.\n",
    "\n",
    "The variables in a study of a cause-and-effect relationship are called the independent and dependent variables. The independent variable is the cause. Its value is independent of other variables in your study. The dependent variable is the effect\n",
    "\n",
    "\n",
    "# 2. What is the concept of simple linear regression? Give a specific example.\n",
    "\n",
    "ANS = \n",
    "\n",
    "The main concept is to make a line fit data points of highly correlated pair of variables such that the root mean square error value is the least. This would mean that we need to make sure that the distance between the fitted regression line and the data points(residuals) is least. Several assumptions are made to make simple linear regression work. Linearity, Independence of variables involved, residuals must be normally distributed are assumptions.\n",
    "\n",
    "\n",
    "\n",
    "#  3. In a linear regression, define the slope.\n",
    "\n",
    "ANS = \n",
    "\n",
    "The slope of a regression line (b) represents the rate of change in y as x changes. Because y is dependent on x, the slope describes the predicted values of y given x. The slope must be calculated before the y-intercept when using a linear regression, as the intercept is calculated using the slope.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  4. Determine the graph's slope, where the lower point on the line is represented as (3, 2) and the higher point is represented as (2, 2).\n",
    "\n",
    "ANS = \n",
    "\n",
    "Slope would be 3/2 or 1.5\n",
    "\n",
    "Ans: If the slope is positive, y increases as x increases, and the function runs \"uphill\" (going left to right). If the slope is zero, y does not change, thus is constant—a horizontal line.\n",
    "\n",
    "\n",
    "\n",
    "#  5. In linear regression, what are the conditions for a positive slope?\n",
    "\n",
    "ANS = \n",
    "\n",
    "If the slope is positive, y increases as x increases, and the function runs \"uphill\" (going left to right). If the slope is zero, y does not change, thus is constant—a horizontal line.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 6. In linear regression, what are the conditions for a negative slope?\n",
    "\n",
    "ANS = \n",
    "\n",
    "For a positive slope, the two linearly related variables must have a negative correlation coefficient. (negative slope)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  7. What is multiple linear regression and how does it work?\n",
    "\n",
    "ANS = \n",
    "\n",
    "Multiple linear regression refers to a statistical technique that uses two or more independent variables to predict the outcome of a dependent variable. The technique enables analysts to determine the variation of the model and the relative contribution of each independent variable in the total variance.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 8. In multiple linear regression, define the number of squares due to error.\n",
    "\n",
    "ANS = \n",
    "\n",
    "Sum of squares (SS) is a statistical tool that is used to identify the dispersion of data as well as how well the data can fit the model in regression analysis. The sum of squares got its name because it is calculated by finding the sum of the squared differences.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 9. In multiple linear regression, define the number of squares due to regression.\n",
    "\n",
    "ANS = \n",
    "\n",
    "Sum of squares is a statistical technique used in regression analysis to determine the dispersion of data points. In a regression analysis, the goal is to determine how well a data series can be fitted to a function that might help to explain how the data series was generated.\n",
    "\n",
    "\n",
    "# 10. In a regression equation, what is multicollinearity?\n",
    "\n",
    "ANS = \n",
    "\n",
    "\n",
    "In regression, \"multicollinearity\" refers to predictors that are correlated with other predictors. Multicollinearity occurs when your model includes multiple factors that are correlated not just to your response variable, but also to each other. In other words, it results when you have factors that are a bit redundant.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # # 11. What is heteroskedasticity, and what does it mean?\n",
    "\n",
    "ANS = \n",
    "\n",
    "Heteroskedasticity (also spelled heteroscedasticity) refers to the error variance, or dependence of scattering, within a minimum of one independent variable within a particular sample.A common cause of variances outside the minimum requirement is often attributed to issues of data quality.\n",
    "\n",
    "\n",
    "\n",
    "# # 12. Describe the concept of ridge regression.\n",
    "\n",
    "ANS = \n",
    "\n",
    "Ridge Regression is a technique for analyzing multiple regression data that suffer from multicollinearity. When multicollinearity occurs, least squares estimates are unbiased, but their variances are large so they may be far from the true value.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 13. Describe the concept of lasso regression.\n",
    "\n",
    "ANS = \n",
    "\n",
    "In statistics and machine learning, lasso (least absolute shrinkage and selection operator; also Lasso or LASSO) is a regression analysis method that performs both variable selection and regularization in order to enhance the prediction accuracy and interpretability of the resulting statistical model.\n",
    "\n",
    "\n",
    "# 14. What is polynomial regression and how does it work?\n",
    "\n",
    "ANS = \n",
    "\n",
    "\n",
    "Polynomial regression models can bend. They can be constructed to the nth-degree to minimize squared error and maximize rsquared. Depending on the nth degree, the line of best fit can have more or less curves. The higher the exponent, the more numerous the curves. y=m0+m1x^1+m2x^2 Here y:dependent variable m0 is the constant mi is the slope and x^i is the dependent variable and so on\n",
    "\n",
    "\n",
    "\n",
    "# 15. Describe the basis function.\n",
    "\n",
    "ANS = \n",
    "\n",
    "This is a generalization of linear regression that essentially replaces each input with a function of the input. (A linear basis function model that uses the identity function is just linear regression.)\n",
    "\n",
    "\n",
    "\n",
    "# 16. Describe how logistic regression works.\n",
    "ANS = \n",
    "\n",
    "Logistic regression measures the relationship between the categorical dependent variable and one or more independent variables by estimating probabilities using a logistic function, which is the cumulative distribution function of logistic distribution. log(p/1-p) is the link function. Logarithmic transformation on the outcome variable allows us to model a non-linear association in a linear way. This is the equation used in Logistic Regression.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
